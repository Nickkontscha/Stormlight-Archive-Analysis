"0","# Same as before but for the characters"
"0","char_words_tokens <- AllBooks %>% "
"0","  select(character, text) %>% "
"0","  filter(character %in% relChars) %>% "
"0","  unnest_tokens(word, text) %>% "
"0","  count(character, word, sort = TRUE) %>% "
"0","  ungroup() %>% "
"0","  filter(!word %in% stopwords)%>% "
"0","  filter(n > 10)"
"0","char_words_ngrams <- AllBooks %>% "
"0","  select(character, text) %>%  "
"0","  filter(character %in% relChars) %>% "
"0","  unnest_tokens(word, text, token = ""skip_ngrams"", n = 2, k = 2) %>% "
"0","  filter(str_count(word, ""\\w+"")  == 2) %>% "
"0","  separate(word, c(""word1"", ""word2""), sep = "" "") %>% "
"0","  filter(!word1 %in% stopwords) %>%"
"0","  filter(!word2 %in% stopwords) %>% "
"0","  unite(word, word1, word2, sep = "" "") %>% "
"0","  count(character, word, sort = TRUE) %>% "
"0","  ungroup() %>% "
"0","  filter(n > 10)"
"0","char_words_tokens$character <- factor(char_words_tokens$character, levels = relChars)"
"0","char_words_ngrams$character <- factor(char_words_ngrams$character, levels = relChars)"
"0","plot_char_words_tokens_tfidf <- char_words_tokens %>% "
"0","  group_by(character) %>%"
"0","  bind_tf_idf(word, character, n) %>% "
"0","  top_n(20, tf_idf) %>% "
"0","  mutate(index = seq(1, length(n), 1)) %>% "
"0","  unite(""ordering"", character, index, sep = ""_"", remove = FALSE) %>% "
"0","  data.frame() %>% "
"0","  mutate(ordering = factor(ordering, levels = ordering)) %>% "
"0","  mutate(idf = idf_smooth(idf)) %>%  "
"0","  mutate(tf_idf = tf*idf)"
"0","plot_char_words_ngrams_tfidf <- char_words_ngrams %>% "
"0","  group_by(character) %>%"
"0","  bind_tf_idf(word, character, n) %>% "
"0","  top_n(20, tf_idf) %>% "
"0","  mutate(index = seq(1, length(n), 1)) %>% "
"0","  unite(""ordering"", character, index, sep = ""_"", remove = FALSE) %>% "
"0","  data.frame() %>% "
"0","  mutate(ordering = factor(ordering, levels = ordering)) %>% "
"0","  mutate(idf = idf_smooth(idf)) %>%  "
"0","  mutate(tf_idf = tf*idf)"
"0","c1_tfidf <- ggplot(plot_char_words_tokens_tfidf, aes(reorder(ordering, tf_idf), tf_idf, fill = character)) +"
"0","  geom_col(show.legend = FALSE, width = 0.8) +"
"0","  facet_wrap(~character, scales = ""free"", drop = TRUE) +"
"0","  scale_x_discrete(breaks = plot_char_words_tokens_tfidf$ordering,"
"0","                   labels = plot_char_words_tokens_tfidf$word) +"
"0","  scale_y_continuous(labels = function(x) x*1000) +"
"0","  labs( y = """","
"0","        x = NULL) +"
"0","  coord_flip()+"
"0","  theme(panel.background = element_rect(fill = ""#ecf0f1"")) + "
"0","  scale_fill_manual(values = swatch()[c(2, 4, 9)]) +"
"0","  ggtitle(""Most Important Terms in the Stormlight Archieve Ordered by Characters"")"
"0","c2_tfidf <- ggplot(plot_char_words_ngrams_tfidf, aes(reorder(ordering, tf_idf), tf_idf, fill = character)) +"
"0","  geom_col(show.legend = FALSE, width = 0.8) +"
"0","  facet_wrap(~character, scales = ""free"", drop = TRUE) +"
"0","  scale_x_discrete(breaks = plot_char_words_ngrams_tfidf$ordering,"
"0","                   labels = plot_char_words_ngrams_tfidf$word) +"
"0","  scale_y_continuous(labels = function(x) x*100) +"
"0","  labs( y = ""scaled tf-idf value"","
"0","        x = NULL) +"
"0","  coord_flip()+"
"0","  theme(panel.background = element_rect(fill = ""#ecf0f1"")) + "
"0","  scale_fill_manual(values = swatch()[c(2, 4, 9)]) "
"0","gA <- ggplotGrob(c1_tfidf)"
"0","gB <- ggplotGrob(c2_tfidf)"
"0","grid::grid.newpage()"
